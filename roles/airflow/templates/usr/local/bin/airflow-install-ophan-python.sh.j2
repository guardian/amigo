#!/bin/sh
GUARDIAN_PYTHON_ZIP=guardian.zip
# Python subdir is replicated in the zip file contents also. So is used
# for the local folder pointer for the pip command as well as build the
# source s3 path.
PYTHON_FOLDER=python
# AIRFLOW_STAGE is exported from the live /etc/sysconfig/airflow which
# is invoked as the EnvironmentFile for the airflow systemd services by
# pattern. It is passed as the Stage variable in the cloudformation step
# in ophan-data-lake.
S3_PATH="s3://ophan-dist/ophan-data-lake/$AIRFLOW_STAGE/airflow-assets/$PYTHON_FOLDER/$GUARDIAN_PYTHON_ZIP"

# Continue to use the Jinja invocation for the airflow_home variable which
# is currently only set in the Airflow role's defaults yaml.

# TODO: move airflow_home to an ENV variable on the image, and move it
# to /home/airflow/ as convention dictates. Which will mean this file
# can then be a static bash script.
echo "Downloading extra python libraries from $S3_PATH"
# Brute force a removal of the folder whether or not it exists already
rm -f {{ airflow_home }}/$PYTHON_FOLDER
aws s3 cp $S3_PATH {{ airflow_home }}/

if [ -e {{ airflow_home }}/$GUARDIAN_PYTHON_ZIP ]; then
	# Inflate / extract the python installable, note that files will now
	# be in airflow_home/python/guardian/ etc.
    unzip -o {{ airflow_home }}/$GUARDIAN_PYTHON_ZIP -d {{ airflow_home }}
    # Delete the downloaded artefact
    rm -f {{ airflow_home }}/$GUARDIAN_PYTHON_ZIP

    # Install against the virtualenv pip binary, as the virtualenv binary
    # is the one used by the instance's airflow systemd service

    # -e is a flag to indicate its a local / editable directory
    {{ airflow_virtualenv_folder }}/bin/pip install -e {{ airflow_home }}/$PYTHON_FOLDER/
else
    echo "WARNING: NO PYTHON MODULE FOUND IN $S3_PATH"
fi
